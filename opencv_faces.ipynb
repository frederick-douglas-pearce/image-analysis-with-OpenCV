{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df89f473-caf3-4850-bcf2-e371a0cc64d8",
   "metadata": {},
   "source": [
    "# Face Detection and Recognition\n",
    "This notebook provides a quick resource for exploring OpenCV's built-in face detection and recognition algorithms, and is inspired by the third section of the following youtube video: https://www.youtube.com/watch?v=oXlwWbU8l2o\n",
    "\n",
    "Original code for the course can be found on the [github profile](https://github.com/jasmcaus/opencv-course) of the course instructor, Jason Dsouza.\n",
    "\n",
    "Images of 'famous' people are used as examples, which were downloaded from the Labelled Faces in the Wild (LFW) dataset, available as part of the following Kaggle competition: https://www.kaggle.com/jessicali9530/lfw-dataset\n",
    "\n",
    "The goal of Face Detection is to identify a rectangular bounding box around each face in an input image. Additional features may be detected as well, e.g. eyes, smile, etc. The goal of Face Recognition is to correctly identify the person based on their facial features. Common practice is to first apply face detection, then apply a facial recognition algorithm to identify the name of the person from features in the detected face image.\n",
    "\n",
    "## References\n",
    "- https://github.com/Kaggle/kaggle-api (you can use the api to download the LFW data)\n",
    "- https://pythonprogramming.net/haar-cascade-object-detection-python-opencv-tutorial/\n",
    "- https://towardsdatascience.com/a-dog-detector-and-breed-classifier-4feb99e1f852 (also see https://github.com/HenryDashwood/dog_breed_classifier)\n",
    "- https://keras.io/guides/transfer_learning/\n",
    "- https://towardsdatascience.com/face-detection-in-2-minutes-using-opencv-python-90f89d7c0f81\n",
    "- https://www.pyimagesearch.com/2014/07/21/detecting-circles-images-using-opencv-hough-circles/\n",
    "- https://stackoverflow.com/questions/20801015/recommended-values-for-opencv-detectmultiscale-parameters\n",
    "- https://docs.opencv.org/4.1.0/d5/d54/group__objdetect.html\n",
    "- https://www.pyimagesearch.com/2018/02/26/face-detection-with-opencv-and-deep-learning/\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08811096-1863-435b-8278-ae2a74f65167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from opencv_tools import load_frame_gray, show_frame, detect_primary_objects, detect_image_objects, draw_detected_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5777731f-42d8-4167-bc2c-c3c3774d2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of base directory containing subfolders with image files for each person\n",
    "dir_root = \"/home/fdpearce/Documents/Projects/data/Images/LFW/lfw-deepfunneled/lfw-deepfunneled\"\n",
    "# Name must match folder name exactly after a single modification: spaces, \" \", are converted to underscores, \"_\" (see get_img_path for details)\n",
    "people = [\"George W Bush\", \"Laura Bush\", \"Vladimir Putin\", \"Gloria Macapagal Arroyo\", \"Arnold Schwarzenegger\", \"Megawati Sukarnoputri\", \\\n",
    "          \"Hugo Chavez\", \"Serena Williams\", \"Colin Powell\", \"Junichiro Koizumi\", \"Jennifer Capriati\"]\n",
    "num_people_with_most_img = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ecddecb-ec35-4ee5-842e-8e00d8fb1df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of People with Images Available = 5749\n",
      "Top 25 People With Most Images, # of Images\n",
      "('George_W_Bush', 530)\n",
      "('Colin_Powell', 236)\n",
      "('Tony_Blair', 144)\n",
      "('Donald_Rumsfeld', 121)\n",
      "('Gerhard_Schroeder', 109)\n",
      "('Ariel_Sharon', 77)\n",
      "('Hugo_Chavez', 71)\n",
      "('Junichiro_Koizumi', 60)\n",
      "('Jean_Chretien', 55)\n",
      "('John_Ashcroft', 53)\n",
      "('Serena_Williams', 52)\n",
      "('Jacques_Chirac', 52)\n",
      "('Vladimir_Putin', 49)\n",
      "('Luiz_Inacio_Lula_da_Silva', 48)\n",
      "('Gloria_Macapagal_Arroyo', 44)\n",
      "('Arnold_Schwarzenegger', 42)\n",
      "('Jennifer_Capriati', 42)\n",
      "('Laura_Bush', 41)\n",
      "('Lleyton_Hewitt', 41)\n",
      "('Hans_Blix', 39)\n",
      "('Alejandro_Toledo', 39)\n",
      "('Nestor_Kirchner', 37)\n",
      "('Andre_Agassi', 36)\n",
      "('Alvaro_Uribe', 35)\n",
      "('Megawati_Sukarnoputri', 33)\n"
     ]
    }
   ],
   "source": [
    "# Print high-level stats, including the number of people with image data, and a list of people with the\n",
    "# most images, plus the # of Images. num_people_with_most_img determines how many people to display results for\n",
    "people_folder = os.listdir(dir_root)\n",
    "num_images_per_folder = [len(os.listdir(os.path.join(dir_root, p))) for p in people_folder]\n",
    "sort_people_num_img = sorted(zip(people_folder, num_images_per_folder), reverse=True, key=lambda pair: pair[1])\n",
    "print(f\"# of People with Images Available = {len(people_folder)}\")\n",
    "print(f\"Top {num_people_with_most_img} People With Most Images, # of Images\")\n",
    "print(*sort_people_num_img[:num_people_with_most_img], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dabf2c55-feff-4cba-a4e9-aa9f68ad2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for creating training data and visualizing/validating results\n",
    "# using functions from opencv_tools imported above\n",
    "def get_img_path(dir_root, person, img_num, img_ext):\n",
    "    \"\"\"Returns the full path to an image by joining the parameters in their input order:\n",
    "    dir_root = directory root, one level above folders for individual people that contain image files\n",
    "    person = person the images are of in a specific subfolder, with spaces between first, last, etc\n",
    "    img_num = a string identifying the individual image of the person\n",
    "    img_ext = file extension of the image files\n",
    "    Image format is roughly dir_root/person/person+_+img_num+_+img_ext, see code for details\n",
    "    \"\"\"\n",
    "    person_fname = \"_\".join(person.split(\" \"))\n",
    "    file_name = \"_\".join([person_fname, img_num])+img_ext\n",
    "    return os.path.join(dir_root, person_fname, file_name)\n",
    "\n",
    "def create_training_data(dir_root, people, person_img_max, detect_params, detect_objects=False, detect_type=\"all\", random_seed=0, verbose=False):\n",
    "    \"\"\"Create training data from the following inputs:\n",
    "    dir_root = a string containing base directory with subfolders containing images for each person\n",
    "    people = a list containing string values, with each string containing a person's name. These are the folder names, EXCEPT for spaces instead of underscores\n",
    "    person_img_max = an integer specifying the maximum number of training images to return for each person. Set this to a value larger than that\n",
    "                     maximum # of images available if you want to process all images\n",
    "    haar_path = a string containing the path to the haar cascade class definition xml file. Files for different features (e.g. face, eyes, etc) can\n",
    "                be downloaded from the following link: https://github.com/opencv/opencv/blob/master/data/haarcascades/\n",
    "    detect_params = a dictionary containing two sets of parameters: 1) 'haar_file', a string specifying the full path to the haar cascade\n",
    "                    xml file to load and 2) 'params' dict to pass to the detectMultiScale method of the haar cascade class. Valid values\n",
    "                    include scaleFactor (default=1.1), minNeighbors (default=3), and minSize. \n",
    "                    The haar_file in 1) can be downloaded from here: https://github.com/opencv/opencv/blob/master/data/haarcascades/\n",
    "    detect_objects = a boolean-like value (True/False, 1/0, etc) that turns on/off object detection. Set to false to conduct a dry run that checks\n",
    "                     how many image files will be processed for each person\n",
    "    detect_type = an optional string specifying the type of detection to perform:\n",
    "                  \"all\": runs detect_all_objects, which returns all objects detected from one execution of the haar class detectMultiScale\n",
    "                  method with the input parameters specified in detect_params. The number of objects detected may vary greatly from image to\n",
    "                  image for a fixed set of input parameters\n",
    "                  \"primary\": runs detect_primary_objects, which performs an iterative process to return a user-specified number of primary objects\n",
    "                  detected in the input image. Essentially, the minNeighbors parameter is adjusted until the desired number of objects are detected\n",
    "    random_seed = an integer that determines the order of the random shuffle applied to images before selecting the training samples\n",
    "    verbose = a boolean-like value that, when truthy, prints additional details during execution for validation/debugging purposes\n",
    "    Output is a tuple with two values:\n",
    "    features = a list containing zero or more lists, with each list containing four values (x, y, w, h) that define the rectangle containing the detected object\n",
    "    labels = a list containing zero or more integer values, with each int specifying the index to a specific person in the input list of people used for training\n",
    "    \"\"\"\n",
    "    random.seed(random_seed)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for person in people:\n",
    "        label = people.index(person)\n",
    "        path = os.path.join(dir_root, \"_\".join(person.split(\" \")))\n",
    "        img_files = os.listdir(path)\n",
    "        random.shuffle(img_files)\n",
    "        img_num = 0\n",
    "        total_detected = 0\n",
    "        num_detected = 0\n",
    "        for img_f in img_files[:min(person_img_max, len(img_files))]:\n",
    "            img_path = os.path.join(path, img_f)\n",
    "            img_num += 1\n",
    "            print(f\"Working on Image # {img_num}: {img_f}\")\n",
    "            if detect_objects:\n",
    "                _, gray = load_frame_gray(img_path, gray_flag=True)\n",
    "                detected_features, detected_labels = detect_image_objects(gray, detect_params, detect_type=detect_type, label=label, verbose=verbose)\n",
    "                num_detected = len(detected_features)\n",
    "                if num_detected:\n",
    "                    total_detected += num_detected\n",
    "                    features.extend(detected_features)\n",
    "                    labels.extend(detected_labels)\n",
    "        print(f\"{img_num} training images with {total_detected} objects identified for {person}\")\n",
    "    return features, labels\n",
    "\n",
    "def show_person_images(dir_root, person, img_nums, img_ext, object_rectangles, rect_color=(0, 0, 0)):\n",
    "    \"\"\"Loop through each each image in the input person's subfolder, whose number is provided in the input list of\n",
    "    strings, img_nums. Show all objects in the input list of objects, object_rectangles.\n",
    "    \"\"\"\n",
    "    for ind, img_n in enumerate(img_nums):\n",
    "        img_path = get_img_path(dir_root, person, img_n, img_ext)\n",
    "        _, gray = load_frame_gray(img_path, gray_flag=True)\n",
    "        gray = draw_detected_objects(gray, object_rectangles[ind], print_detected=True, frame_to_show=None, rect_color=rect_color)\n",
    "        show_frame(gray, f\"Primary Objects(s) Detected for {person}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4620061-61e9-4f26-bbfe-43758cf660fa",
   "metadata": {},
   "source": [
    "### Load an Example Image and Convert to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c047bf-d25f-45b4-b98f-78a59e198cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "people = [\"Megawati Sukarnoputri\"] # for testing purposes\n",
    "person = people[0]\n",
    "img_num = \"0017\"\n",
    "#img_num = \"0027\"\n",
    "img_ext = \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bdb0360-24ea-414c-b18b-1fb651786693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of Example Grayscale Image = (250, 250)\n"
     ]
    }
   ],
   "source": [
    "# Parse parameters to build path to a single image, img_path, then load grayscale image\n",
    "per_fname = \"_\".join(person.split(\" \"))\n",
    "img_path = os.path.join(dir_root, per_fname, \"_\".join([per_fname, img_num])+img_ext)\n",
    "_, gray_face = load_frame_gray(img_path, gray_flag=True)\n",
    "print(f\"Size of Example Grayscale Image = {gray_face.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a657b4-3001-4e6a-b14c-10bb2fe365cb",
   "metadata": {},
   "source": [
    "## Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03584fff-2ebe-4b0f-bbfb-d74f5521d9ab",
   "metadata": {},
   "source": [
    "The first step is to download Haar Cascades xml file for frontal face detection from the following link:\n",
    "\n",
    "https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "\n",
    "If you want to follow the code below, then you should also download the eye and smile detection xml files from the haarcascades folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba68f3e-ef8b-47e3-a663-7a6e665448e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "haar_cascade_params = {\n",
    "    'face': {\n",
    "        'haar_file': '/home/fdpearce/Documents/Projects/models/haar_cascades/haar_cascade_frontalface.xml',\n",
    "        'params': {\n",
    "            'scaleFactor': 1.1,\n",
    "            'minNeighbors': 4,\n",
    "            'minSize': (20, 20)\n",
    "        }\n",
    "    },\n",
    "    'eye': {\n",
    "        'haar_file': '/home/fdpearce/Documents/Projects/models/haar_cascades/haar_cascade_eye.xml',\n",
    "        'num_primary_obj': 2,\n",
    "        'params': {\n",
    "            'scaleFactor': 1.1,\n",
    "            'minNeighbors': 4,\n",
    "            'minSize': (20, 20)\n",
    "        }\n",
    "    },\n",
    "    'smile': {\n",
    "        'haar_file': '/home/fdpearce/Documents/Projects/models/haar_cascades/haar_cascade_smile.xml',\n",
    "        'params': {\n",
    "            'scaleFactor': 1.1,\n",
    "            'minNeighbors': 8,\n",
    "            'minSize': (20, 20)\n",
    "        }     \n",
    "    }\n",
    "}\n",
    "haar_image = gray_face.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebad2d2b-4f12-4160-a8c3-a88cca6dfcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n"
     ]
    }
   ],
   "source": [
    "# Face detection\n",
    "detection_obj = 'face'\n",
    "haar_obj = haar_cascade_params[detection_obj]\n",
    "detected_face_rects = detect_primary_objects(haar_image, verbose=True, **haar_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dc74e30-cbef-40ef-935c-2940ccdb4586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial # of Objects Detected = 2\n",
      "Final # of Objects Detected = 2\n"
     ]
    }
   ],
   "source": [
    "# Eye detection\n",
    "detection_obj = 'eye'\n",
    "haar_obj = haar_cascade_params[detection_obj]\n",
    "detected_eye_rects = detect_primary_objects(haar_image, verbose=True, **haar_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e87bd89a-1d8d-43b5-ae65-894f28321f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial # of Objects Detected = 4\n",
      "Iteration # = 1\n",
      "minNeighbors = 10\n",
      "Iteration # = 2\n",
      "minNeighbors = 14\n",
      "Iteration # = 3\n",
      "minNeighbors = 16\n",
      "Iteration # = 4\n",
      "minNeighbors = 20\n",
      "Iteration # = 5\n",
      "minNeighbors = 26\n",
      "Iteration # = 6\n",
      "minNeighbors = 34\n",
      "Final # of Objects Detected = 1\n"
     ]
    }
   ],
   "source": [
    "# Smile detection\n",
    "detection_obj = 'smile'\n",
    "haar_obj = haar_cascade_params[detection_obj]\n",
    "detected_smile_rects = detect_primary_objects(haar_image, verbose=True, **haar_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceb35bfa-51d4-46d7-af90-c56b39b4370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Faces Found = 1\n",
      "# of Eyes Found = 2\n",
      "# of Smiles Found = 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"# of Faces Found = {len(detected_face_rects)}\")\n",
    "print(f\"# of Eyes Found = {len(detected_eye_rects)}\")\n",
    "print(f\"# of Smiles Found = {len(detected_smile_rects)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d354692f-625d-427f-bcaf-6691f9743651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 0 Location: x=95, y=142, w=58, h=29\n"
     ]
    }
   ],
   "source": [
    "# Print detected smile(s) coordinates, and optionally show on original image\n",
    "haar_image = draw_detected_objects(haar_image, detected_smile_rects, print_detected=True, frame_to_show=None, rect_color=(255, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "084e094c-e03e-4172-ae73-da04c71ef2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 0 Location: x=91, y=99, w=29, h=29\n",
      "Object 1 Location: x=131, y=99, w=30, h=30\n"
     ]
    }
   ],
   "source": [
    "# Print detected eye(s) coordinates, and optionally show on original image\n",
    "haar_image = draw_detected_objects(haar_image, detected_eye_rects, print_detected=True, frame_to_show=None, rect_color=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d4f60c6-5f64-4780-9a6d-6349c14b44a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 0 Location: x=68, y=67, w=119, h=119\n"
     ]
    }
   ],
   "source": [
    "# Print detected face(s) coordinates, and optionally show on original image\n",
    "haar_image = draw_detected_objects(haar_image, detected_face_rects, print_detected=True, frame_to_show=None, rect_color=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45157fce-0d33-436f-9fee-841a7830be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_frame(haar_image, f\"Faces(s) Detected in Image of {person}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6c0e43-153e-490b-841b-767ce8887ab4",
   "metadata": {},
   "source": [
    "### Face Detection on Training Data\n",
    "First perform face detection using detection type of 'all', i.e. detection parameters are fixed to those provided at input and all detected objects are returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25a059c2-d9c2-497e-a298-6bd45a8de55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Image # 1: Megawati_Sukarnoputri_0020.jpg\n",
      "# of Objects Detected = 1\n",
      "66, 68, 119, 119\n",
      "Working on Image # 2: Megawati_Sukarnoputri_0006.jpg\n",
      "# of Objects Detected = 1\n",
      "73, 73, 104, 104\n",
      "Working on Image # 3: Megawati_Sukarnoputri_0021.jpg\n",
      "# of Objects Detected = 1\n",
      "68, 70, 115, 115\n",
      "Working on Image # 4: Megawati_Sukarnoputri_0028.jpg\n",
      "# of Objects Detected = 1\n",
      "66, 69, 117, 117\n",
      "Working on Image # 5: Megawati_Sukarnoputri_0027.jpg\n",
      "# of Objects Detected = 2\n",
      "7, 49, 102, 102\n",
      "74, 69, 109, 109\n",
      "Working on Image # 6: Megawati_Sukarnoputri_0005.jpg\n",
      "# of Objects Detected = 1\n",
      "69, 65, 113, 113\n",
      "Working on Image # 7: Megawati_Sukarnoputri_0016.jpg\n",
      "# of Objects Detected = 1\n",
      "67, 69, 114, 114\n",
      "Working on Image # 8: Megawati_Sukarnoputri_0023.jpg\n",
      "# of Objects Detected = 1\n",
      "70, 71, 110, 110\n",
      "Working on Image # 9: Megawati_Sukarnoputri_0029.jpg\n",
      "# of Objects Detected = 1\n",
      "66, 70, 115, 115\n",
      "Working on Image # 10: Megawati_Sukarnoputri_0012.jpg\n",
      "# of Objects Detected = 1\n",
      "53, 54, 133, 133\n",
      "Working on Image # 11: Megawati_Sukarnoputri_0004.jpg\n",
      "# of Objects Detected = 1\n",
      "71, 75, 106, 106\n",
      "Working on Image # 12: Megawati_Sukarnoputri_0014.jpg\n",
      "# of Objects Detected = 1\n",
      "75, 73, 103, 103\n",
      "Working on Image # 13: Megawati_Sukarnoputri_0030.jpg\n",
      "# of Objects Detected = 1\n",
      "66, 66, 117, 117\n",
      "Working on Image # 14: Megawati_Sukarnoputri_0026.jpg\n",
      "# of Objects Detected = 1\n",
      "70, 67, 114, 114\n",
      "Working on Image # 15: Megawati_Sukarnoputri_0033.jpg\n",
      "# of Objects Detected = 1\n",
      "74, 75, 101, 101\n",
      "Working on Image # 16: Megawati_Sukarnoputri_0022.jpg\n",
      "# of Objects Detected = 1\n",
      "73, 72, 108, 108\n",
      "Working on Image # 17: Megawati_Sukarnoputri_0002.jpg\n",
      "# of Objects Detected = 1\n",
      "66, 67, 118, 118\n",
      "Working on Image # 18: Megawati_Sukarnoputri_0017.jpg\n",
      "# of Objects Detected = 1\n",
      "68, 67, 119, 119\n",
      "Working on Image # 19: Megawati_Sukarnoputri_0009.jpg\n",
      "# of Objects Detected = 1\n",
      "71, 72, 109, 109\n",
      "Working on Image # 20: Megawati_Sukarnoputri_0025.jpg\n",
      "# of Objects Detected = 2\n",
      "3, 10, 74, 74\n",
      "67, 68, 115, 115\n",
      "Working on Image # 21: Megawati_Sukarnoputri_0031.jpg\n",
      "# of Objects Detected = 2\n",
      "162, 8, 56, 56\n",
      "65, 68, 117, 117\n",
      "Working on Image # 22: Megawati_Sukarnoputri_0008.jpg\n",
      "# of Objects Detected = 1\n",
      "71, 71, 108, 108\n",
      "Working on Image # 23: Megawati_Sukarnoputri_0007.jpg\n",
      "# of Objects Detected = 1\n",
      "66, 65, 117, 117\n",
      "Working on Image # 24: Megawati_Sukarnoputri_0032.jpg\n",
      "# of Objects Detected = 1\n",
      "68, 70, 115, 115\n",
      "Working on Image # 25: Megawati_Sukarnoputri_0011.jpg\n",
      "# of Objects Detected = 1\n",
      "70, 69, 113, 113\n",
      "Working on Image # 26: Megawati_Sukarnoputri_0013.jpg\n",
      "# of Objects Detected = 1\n",
      "68, 68, 114, 114\n",
      "Working on Image # 27: Megawati_Sukarnoputri_0001.jpg\n",
      "# of Objects Detected = 1\n",
      "71, 68, 112, 112\n",
      "Working on Image # 28: Megawati_Sukarnoputri_0019.jpg\n",
      "# of Objects Detected = 2\n",
      "69, 69, 112, 112\n",
      "86, 161, 80, 80\n",
      "Working on Image # 29: Megawati_Sukarnoputri_0003.jpg\n",
      "# of Objects Detected = 2\n",
      "92, 46, 86, 86\n",
      "70, 77, 107, 107\n",
      "Working on Image # 30: Megawati_Sukarnoputri_0015.jpg\n",
      "# of Objects Detected = 1\n",
      "73, 71, 106, 106\n",
      "30 training images with 35 objects identified for Megawati Sukarnoputri\n",
      "# of Features = 35\n",
      "# of Labels = 35\n"
     ]
    }
   ],
   "source": [
    "person_img_max = 30\n",
    "detect_obj = 'face'\n",
    "detect_type = 'all'\n",
    "haar_obj = haar_cascade_params[detect_obj]\n",
    "features, labels = create_training_data(dir_root, people, person_img_max, haar_obj, detect_objects=True, detect_type=detect_type, verbose=True)\n",
    "print(f\"# of Features = {len(features)}\")\n",
    "print(f\"# of Labels = {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adad592d-227f-432f-a312-b793610f87f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 0 Location: x=92, y=46, w=86, h=86\n",
      "Object 1 Location: x=70, y=77, w=107, h=107\n",
      "Object 0 Location: x=69, y=69, w=112, h=112\n",
      "Object 1 Location: x=86, y=161, w=80, h=80\n",
      "Object 0 Location: x=3, y=10, w=74, h=74\n",
      "Object 1 Location: x=67, y=68, w=115, h=115\n",
      "Object 0 Location: x=7, y=49, w=102, h=102\n",
      "Object 1 Location: x=74, y=69, w=109, h=109\n",
      "Object 0 Location: x=162, y=8, w=56, h=56\n",
      "Object 1 Location: x=65, y=68, w=117, h=117\n"
     ]
    }
   ],
   "source": [
    "# Visually inspect example images and the bounding box detected by the face recognition algorithm\n",
    "# Use the verbose setting above to print out bounding boxes\n",
    "person = people[0]\n",
    "img_nums = [\"0003\", \"0019\", \"0025\", \"0027\", \"0031\"]\n",
    "img_ext = \".jpg\"\n",
    "# Megawati Sukarnoputri: 'all' examples where 2 faces detected instead of one\n",
    "face_rectangles = [[[92, 46, 86, 86], [70, 77, 107, 107]], \\\n",
    "                   [[69, 69, 112, 112], [86, 161, 80, 80]], \\\n",
    "                   [[3, 10, 74, 74], [67, 68, 115, 115]], \\\n",
    "                   [[7, 49, 102, 102], [74, 69, 109, 109]], \\\n",
    "                   [[162, 8, 56, 56], [65, 68, 117, 117]]]\n",
    "show_person_images(dir_root, person, img_nums, img_ext, face_rectangles, rect_color=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1816058-18ce-4bf9-a343-5134746fa7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Image # 1: Megawati_Sukarnoputri_0020.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "66, 68, 119, 119\n",
      "Working on Image # 2: Megawati_Sukarnoputri_0006.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "73, 73, 104, 104\n",
      "Working on Image # 3: Megawati_Sukarnoputri_0021.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "68, 70, 115, 115\n",
      "Working on Image # 4: Megawati_Sukarnoputri_0028.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "66, 69, 117, 117\n",
      "Working on Image # 5: Megawati_Sukarnoputri_0027.jpg\n",
      "Initial # of Objects Detected = 2\n",
      "Iteration # = 1\n",
      "minNeighbors = 6\n",
      "Iteration # = 2\n",
      "minNeighbors = 10\n",
      "Iteration # = 3\n",
      "minNeighbors = 16\n",
      "Iteration # = 4\n",
      "minNeighbors = 24\n",
      "Final # of Objects Detected = 1\n",
      "74, 69, 109, 109\n",
      "Working on Image # 6: Megawati_Sukarnoputri_0005.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "69, 65, 113, 113\n",
      "Working on Image # 7: Megawati_Sukarnoputri_0016.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "67, 69, 114, 114\n",
      "Working on Image # 8: Megawati_Sukarnoputri_0023.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "70, 71, 110, 110\n",
      "Working on Image # 9: Megawati_Sukarnoputri_0029.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "66, 70, 115, 115\n",
      "Working on Image # 10: Megawati_Sukarnoputri_0012.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "53, 54, 133, 133\n",
      "Working on Image # 11: Megawati_Sukarnoputri_0004.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "71, 75, 106, 106\n",
      "Working on Image # 12: Megawati_Sukarnoputri_0014.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "75, 73, 103, 103\n",
      "Working on Image # 13: Megawati_Sukarnoputri_0030.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "66, 66, 117, 117\n",
      "Working on Image # 14: Megawati_Sukarnoputri_0026.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "70, 67, 114, 114\n",
      "Working on Image # 15: Megawati_Sukarnoputri_0033.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "74, 75, 101, 101\n",
      "Working on Image # 16: Megawati_Sukarnoputri_0022.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "73, 72, 108, 108\n",
      "Working on Image # 17: Megawati_Sukarnoputri_0002.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "66, 67, 118, 118\n",
      "Working on Image # 18: Megawati_Sukarnoputri_0017.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "68, 67, 119, 119\n",
      "Working on Image # 19: Megawati_Sukarnoputri_0009.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "71, 72, 109, 109\n",
      "Working on Image # 20: Megawati_Sukarnoputri_0025.jpg\n",
      "Initial # of Objects Detected = 2\n",
      "Iteration # = 1\n",
      "minNeighbors = 6\n",
      "Iteration # = 2\n",
      "minNeighbors = 10\n",
      "Iteration # = 3\n",
      "minNeighbors = 16\n",
      "Final # of Objects Detected = 1\n",
      "67, 68, 115, 115\n",
      "Working on Image # 21: Megawati_Sukarnoputri_0031.jpg\n",
      "Initial # of Objects Detected = 2\n",
      "Iteration # = 1\n",
      "minNeighbors = 6\n",
      "Iteration # = 2\n",
      "minNeighbors = 10\n",
      "Final # of Objects Detected = 1\n",
      "65, 68, 117, 117\n",
      "Working on Image # 22: Megawati_Sukarnoputri_0008.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "71, 71, 108, 108\n",
      "Working on Image # 23: Megawati_Sukarnoputri_0007.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "66, 65, 117, 117\n",
      "Working on Image # 24: Megawati_Sukarnoputri_0032.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "68, 70, 115, 115\n",
      "Working on Image # 25: Megawati_Sukarnoputri_0011.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "70, 69, 113, 113\n",
      "Working on Image # 26: Megawati_Sukarnoputri_0013.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "68, 68, 114, 114\n",
      "Working on Image # 27: Megawati_Sukarnoputri_0001.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "71, 68, 112, 112\n",
      "Working on Image # 28: Megawati_Sukarnoputri_0019.jpg\n",
      "Initial # of Objects Detected = 2\n",
      "Iteration # = 1\n",
      "minNeighbors = 6\n",
      "Iteration # = 2\n",
      "minNeighbors = 10\n",
      "Final # of Objects Detected = 1\n",
      "69, 69, 112, 112\n",
      "Working on Image # 29: Megawati_Sukarnoputri_0003.jpg\n",
      "Initial # of Objects Detected = 2\n",
      "Iteration # = 1\n",
      "minNeighbors = 6\n",
      "Final # of Objects Detected = 1\n",
      "70, 77, 107, 107\n",
      "Working on Image # 30: Megawati_Sukarnoputri_0015.jpg\n",
      "Initial # of Objects Detected = 1\n",
      "Final # of Objects Detected = 1\n",
      "73, 71, 106, 106\n",
      "30 training images with 30 objects identified for Megawati Sukarnoputri\n",
      "# of Features = 30\n",
      "# of Labels = 30\n"
     ]
    }
   ],
   "source": [
    "# Now perform face detection using detection type of 'primary' for comparison\n",
    "detect_type = 'primary'\n",
    "haar_obj = haar_cascade_params[detect_obj]\n",
    "features, labels = create_training_data(dir_root, people, person_img_max, haar_obj, detect_objects=True, detect_type=detect_type, verbose=True)\n",
    "print(f\"# of Features = {len(features)}\")\n",
    "print(f\"# of Labels = {len(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "539e0ca9-d5c1-4d8b-9057-0bc35008253b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object 0 Location: x=70, y=77, w=107, h=107\n",
      "Object 0 Location: x=69, y=69, w=112, h=112\n",
      "Object 0 Location: x=67, y=68, w=115, h=115\n",
      "Object 0 Location: x=74, y=69, w=109, h=109\n",
      "Object 0 Location: x=65, y=68, w=117, h=117\n"
     ]
    }
   ],
   "source": [
    "face_rectangles = [[[70, 77, 107, 107]], \\\n",
    "                   [[69, 69, 112, 112]], \\\n",
    "                   [[67, 68, 115, 115]], \\\n",
    "                   [[74, 69, 109, 109]], \\\n",
    "                   [[65, 68, 117, 117]]]\n",
    "show_person_images(dir_root, person, img_nums, img_ext, face_rectangles, rect_color=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a32bf7-6694-4455-9679-5e56cea19398",
   "metadata": {},
   "source": [
    "### 2. Train Face Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfa0419-ab32-46ef-83ac-ccd1f325e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_recognizer_data = False\n",
    "face_recognizer = cv.face.LBPHFaceRecognizer_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7954fac-95cf-4d7f-8220-bead53aea7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.array(features, dtype=\"object\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85fc96f-d9fc-4dd4-be7e-b881a835b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer.train(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a1b1d-adb5-4d54-a99d-c2871fca2842",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_recognizer_data:\n",
    "    face_recognizer.save(\"face_recognizer.yml\")\n",
    "    np.save(\"features.npy\", features)\n",
    "    np.save(\"labels.npy\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f87352c-4698-45d7-90e7-28e44866b6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc241e-b865-40b6-9463-ab35e66bc63e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
